{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfaea3c3-d369-42da-971b-bb20667d75ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving GDP data (product 14100288): HTTPSConnectionPool(host='www150.statcan.gc.ca', port=443): Max retries exceeded with url: /t1/wds/rest/getFullTableDownloadCSV/14100288/en (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1017)')))\n",
      "Error retrieving Employment data (product 14100287): HTTPSConnectionPool(host='www150.statcan.gc.ca', port=443): Max retries exceeded with url: /t1/wds/rest/getFullTableDownloadCSV/14100287/en (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1017)')))\n",
      "Error retrieving CPI data (product 14100289): HTTPSConnectionPool(host='www150.statcan.gc.ca', port=443): Max retries exceeded with url: /t1/wds/rest/getFullTableDownloadCSV/14100289/en (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1017)')))\n",
      "Merging GDP and Employment...\n",
      "Error merging datasets: name 'df_gdp' is not defined\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import io\n",
    "import gc\n",
    "\n",
    "def fetch_statcan_data(product_id):\n",
    "    \"\"\"\n",
    "    Retrieves the full table (as a zipped CSV) from Statistics Canada using the getFullTableDownloadCSV endpoint.\n",
    "    Appends '/en' to the product_id to request the English CSV version.\n",
    "    \"\"\"\n",
    "    url = f\"https://www150.statcan.gc.ca/t1/wds/rest/getFullTableDownloadCSV/{product_id}/en\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if data.get(\"status\") != \"SUCCESS\":\n",
    "        raise ValueError(f\"Error retrieving data for product id {product_id}: {data}\")\n",
    "    download_url = data.get(\"object\")\n",
    "    print(f\"Downloading CSV from: {download_url}\")\n",
    "    \n",
    "    # Download the ZIP file containing the CSV\n",
    "    zip_response = requests.get(download_url)\n",
    "    zip_response.raise_for_status()\n",
    "    \n",
    "    # Extract the CSV from the ZIP file (assumes one CSV file in the archive)\n",
    "    with zipfile.ZipFile(io.BytesIO(zip_response.content)) as z:\n",
    "        csv_filename = z.namelist()[0]\n",
    "        # Use low_memory=False to avoid dtype warnings and possible issues\n",
    "        df = pd.read_csv(z.open(csv_filename), low_memory=False)\n",
    "    return df\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Customize these product IDs with the ones from your cubes CSV (full table download)\n",
    "# --------------------------------------------------------------------------\n",
    "product_id_gdp = \"14100288\"   \n",
    "product_id_emp = \"14100287\"   \n",
    "product_id_cpi = \"14100289\"   \n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Retrieve each dataset\n",
    "# --------------------------------------------------------------------------\n",
    "try:\n",
    "    df_gdp = fetch_statcan_data(product_id_gdp)\n",
    "    print(f\"GDP data shape (raw): {df_gdp.shape}\")\n",
    "    # Filter for Canada and keep only the needed columns\n",
    "    df_gdp = df_gdp[df_gdp['GEO'] == 'Canada']\n",
    "    df_gdp = df_gdp[['REF_DATE', 'VALUE']].rename(columns={'REF_DATE': 'date', 'VALUE': 'GDP'})\n",
    "    # Group by date to avoid duplicates blowing up merges\n",
    "    df_gdp = df_gdp.groupby('date', as_index=False)['GDP'].mean()\n",
    "    # Convert to numeric (downcast to save memory)\n",
    "    df_gdp['GDP'] = pd.to_numeric(df_gdp['GDP'], errors='coerce', downcast='float')\n",
    "    df_gdp['date'] = pd.to_datetime(df_gdp['date'], errors='coerce')\n",
    "    print(f\"GDP data shape (filtered & grouped): {df_gdp.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving GDP data (product {product_id_gdp}): {e}\")\n",
    "\n",
    "try:\n",
    "    df_emp = fetch_statcan_data(product_id_emp)\n",
    "    print(f\"Employment data shape (raw): {df_emp.shape}\")\n",
    "    df_emp = df_emp[df_emp['GEO'] == 'Canada']\n",
    "    df_emp = df_emp[['REF_DATE', 'VALUE']].rename(columns={'REF_DATE': 'date', 'VALUE': 'Employment'})\n",
    "    df_emp = df_emp.groupby('date', as_index=False)['Employment'].mean()\n",
    "    df_emp['Employment'] = pd.to_numeric(df_emp['Employment'], errors='coerce', downcast='float')\n",
    "    df_emp['date'] = pd.to_datetime(df_emp['date'], errors='coerce')\n",
    "    print(f\"Employment data shape (filtered & grouped): {df_emp.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving Employment data (product {product_id_emp}): {e}\")\n",
    "\n",
    "try:\n",
    "    df_cpi = fetch_statcan_data(product_id_cpi)\n",
    "    print(f\"CPI data shape (raw): {df_cpi.shape}\")\n",
    "    df_cpi = df_cpi[df_cpi['GEO'] == 'Canada']\n",
    "    df_cpi = df_cpi[['REF_DATE', 'VALUE']].rename(columns={'REF_DATE': 'date', 'VALUE': 'CPI'})\n",
    "    df_cpi = df_cpi.groupby('date', as_index=False)['CPI'].mean()\n",
    "    df_cpi['CPI'] = pd.to_numeric(df_cpi['CPI'], errors='coerce', downcast='float')\n",
    "    df_cpi['date'] = pd.to_datetime(df_cpi['date'], errors='coerce')\n",
    "    print(f\"CPI data shape (filtered & grouped): {df_cpi.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving CPI data (product {product_id_cpi}): {e}\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Merge the datasets\n",
    "# --------------------------------------------------------------------------\n",
    "try:\n",
    "    # Merge GDP and Employment with an inner join to avoid massive expansions\n",
    "    print(\"Merging GDP and Employment...\")\n",
    "    df_temp = pd.merge(df_gdp, df_emp, on='date', how='inner')\n",
    "    print(f\"Shape after GDP+Employment merge: {df_temp.shape}\")\n",
    "\n",
    "    # Merge with CPI\n",
    "    print(\"Merging with CPI...\")\n",
    "    df_merged = pd.merge(df_temp, df_cpi, on='date', how='inner')\n",
    "    print(f\"Final shape after merging CPI: {df_merged.shape}\")\n",
    "\n",
    "    df_merged.sort_values(by='date', inplace=True)\n",
    "    df_merged.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Créer le dossier 'macroeconomics' s'il n'existe pas\n",
    "    output_folder = \"macroeconomics\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Récupérer la date d'aujourd'hui au format AAAAMMJJ\n",
    "    today = datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "    # Construire le nom de fichier en ajoutant la date avant l'extension\n",
    "    output_file = os.path.join(output_folder, f\"canada_macro_data_{today}.csv\")\n",
    "    df_merged.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"Merged data saved to '{output_file}'\")\n",
    "\n",
    "    # Cleanup\n",
    "    del df_temp, df_merged\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(f\"Error merging datasets: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
