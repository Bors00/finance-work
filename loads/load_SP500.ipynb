{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ab3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "import json\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "##########################################\n",
    "# Connexion à la base de données PostgreSQL\n",
    "##########################################\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"stocks_db\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"db\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Récupérer la liste des colonnes existantes dans la table stocks\n",
    "cur.execute(\"SELECT column_name FROM information_schema.columns WHERE table_name = 'stocks';\")\n",
    "db_columns_map = {row[0].lower(): row[0] for row in cur.fetchall()}\n",
    "\n",
    "##########################################\n",
    "# Définition des colonnes attendues et fonctions utilitaires\n",
    "##########################################\n",
    "\n",
    "expected_columns = {\n",
    "    \"ticker\", \"longName\", \"shortName\", \"sector\", \"industry\", \"country\", \"fullTimeEmployees\",\n",
    "    \"city\", \"state\", \"zip\", \"website\", \"phone\", \"longBusinessSummary\", \"exchange\", \"quoteType\",\n",
    "    \"marketCap\", \"enterpriseValue\", \"forwardEps\", \"trailingPE\", \"dividendRate\", \"dividendYield\",\n",
    "    \"beta\", \"priceToBook\", \"pegRatio\", \"fiftyDayAverage\", \"twoHundredDayAverage\", \"fiftyTwoWeekHigh\",\n",
    "    \"fiftyTwoWeekLow\", \"52WeekChange\", \"SandP52WeekChange\", \"sharesOutstanding\", \"floatShares\", \"bookValue\", \"exDividendDate\",\n",
    "    \"earningsTimestamp\", \"earningsQuarterlyGrowth\", \"revenueQuarterlyGrowth\", \"lastFiscalYearEnd\",\n",
    "    \"nextFiscalYearEnd\", \"mostRecentQuarter\", \"shortRatio\", \"sharesShort\", \"sharesPercentSharesOut\",\n",
    "    \"priceHint\", \"regularMarketOpen\", \"regularMarketDayHigh\", \"regularMarketDayLow\", \"regularMarketVolume\",\n",
    "    \"open\", \"high\", \"low\", \"close\", \"volume\", \"indice\", \"historical_start\", \"historical_end\"\n",
    "}\n",
    "\n",
    "# Mapping attendu en ignorant la casse\n",
    "expected_columns_map = {col.lower(): col for col in expected_columns}\n",
    "\n",
    "# Ensemble des colonnes de type date (en minuscules)\n",
    "date_columns = {\"exdividenddate\", \"lastfiscalyearend\", \"nextfiscalyearend\", \"mostrecentquarter\", \"historical_start\", \"historical_end\"}\n",
    "\n",
    "def convert_date(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if not isinstance(value, str):\n",
    "        value = str(value)\n",
    "    if not value or value.strip() in [\"\", \"N/A\", \"null\"]:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        datetime.strptime(value, \"%Y-%m-%d\")\n",
    "        return value\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        dt = datetime.fromisoformat(value)\n",
    "        return dt.strftime(\"%Y-%m-%d\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        ts = float(value)\n",
    "        ts_int = int(ts)\n",
    "        if len(str(ts_int)) > 10:\n",
    "            ts_int = ts_int / 1000\n",
    "        return datetime.fromtimestamp(ts_int).strftime(\"%Y-%m-%d\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la conversion du timestamp {value}: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_value(key, value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, str) and value.strip() == \"\":\n",
    "        return None\n",
    "    if key in date_columns:\n",
    "        return convert_date(value)\n",
    "    try:\n",
    "        stripped = value.strip() if isinstance(value, str) else value\n",
    "        num = float(stripped)\n",
    "        if num.is_integer():\n",
    "            return int(num)\n",
    "        return num\n",
    "    except Exception:\n",
    "        return value\n",
    "\n",
    "##########################################\n",
    "# Fonctions pour le traitement des fichiers\n",
    "##########################################\n",
    "\n",
    "def extract_date_from_filename(filepath, base_pattern):\n",
    "    filename = os.path.basename(filepath)\n",
    "    pattern = re.escape(base_pattern) + r\"_(\\d{8})\\.csv$\"\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        date_str = match.group(1)\n",
    "        return datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    return None\n",
    "\n",
    "def get_new_files(directory, base_pattern, last_date_file):\n",
    "    \"\"\"\n",
    "    Récupère tous les fichiers dont le nom correspond à 'base_pattern_*.csv'\n",
    "    en ignorant la date du fichier (on lit tous les fichiers trouvés).\n",
    "    Retourne une liste de tuples (date, chemin_du_fichier) triés par date.\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(directory, base_pattern + \"_*.csv\")\n",
    "    files = glob.glob(pattern)\n",
    "    new_files = []\n",
    "    for file in files:\n",
    "        file_date = extract_date_from_filename(file, base_pattern)\n",
    "        if file_date:\n",
    "            new_files.append((file_date, file))\n",
    "    new_files.sort(key=lambda x: x[0])\n",
    "    return new_files, None\n",
    "\n",
    "##########################################\n",
    "# Récupération des fichiers à traiter\n",
    "##########################################\n",
    "\n",
    "# --- Fichiers de Stocks ---\n",
    "stocks_files = []  # Liste de tuples (date, chemin, type) où type est \"sp500\" ou \"tsx\"\n",
    "for base, file_type in [(\"sp500_stocks_info\", \"sp500\")]:\n",
    "    last_date_file = os.path.join(\"stocks\", f\"last_processed_{file_type}.txt\")\n",
    "    new_files, _ = get_new_files(\"stocks\", base, last_date_file)\n",
    "    for file_date, file_path in new_files:\n",
    "        stocks_files.append((file_date, file_path, file_type))\n",
    "stocks_files.sort(key=lambda x: x[0])\n",
    "\n",
    "\n",
    "##########################################\n",
    "# Traitement et insertion dans la base de données\n",
    "##########################################\n",
    "\n",
    "# --- Insertion des Stocks ---\n",
    "for file_date, csv_filename, file_type in stocks_files:\n",
    "    with open(csv_filename, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            stock_data = {}\n",
    "            for key, value in row.items():\n",
    "                lower_key = key.lower()\n",
    "                if lower_key in expected_columns_map and lower_key in db_columns_map:\n",
    "                    db_col = db_columns_map[lower_key]\n",
    "                    stock_data[db_col] = convert_value(lower_key, value)\n",
    "            if file_type == \"tsx\":\n",
    "                stock_data[db_columns_map[\"indice\"]] = \"TSX\"\n",
    "            historical_json = row.get(\"historical\", None)\n",
    "            if stock_data:\n",
    "                cols = list(stock_data.keys())\n",
    "                cols_quoted = ','.join([f'\"{col}\"' for col in cols])\n",
    "                values = [stock_data[col] for col in cols]\n",
    "                placeholders = ','.join(['%s'] * len(values))\n",
    "                insert_query = (\n",
    "                    f\"INSERT INTO stocks ({cols_quoted}) \"\n",
    "                    f\"VALUES ({placeholders}) \"\n",
    "                    \"ON CONFLICT (ticker) DO NOTHING;\"\n",
    "                )\n",
    "                try:\n",
    "                    cur.execute(insert_query, values)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lors de l'insertion dans stocks pour {row.get('ticker')}: {e}\")\n",
    "            if historical_json and historical_json != \"N/A\":\n",
    "                try:\n",
    "                    historical_data = json.loads(historical_json)\n",
    "                    for record in historical_data:\n",
    "                        date_val = convert_date(record.get(\"Date\"))\n",
    "                        if not date_val:\n",
    "                            continue\n",
    "                        open_val = record.get(\"Open\")\n",
    "                        high_val = record.get(\"High\")\n",
    "                        low_val = record.get(\"Low\")\n",
    "                        close_val = record.get(\"Close\")\n",
    "                        volume_val = record.get(\"Volume\")\n",
    "                        insert_prices_query = \"\"\"\n",
    "                        INSERT INTO stock_prices (ticker, date, open, high, low, close, volume)\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "                        \"\"\"\n",
    "                        ticker_val = stock_data.get(\"ticker\", row.get(\"ticker\"))\n",
    "                        cur.execute(insert_prices_query, (\n",
    "                            ticker_val,\n",
    "                            date_val,\n",
    "                            open_val,\n",
    "                            high_val,\n",
    "                            low_val,\n",
    "                            close_val,\n",
    "                            volume_val\n",
    "                        ))\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lors du traitement des données historiques pour {row.get('ticker')}: {e}\")\n",
    "            conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"✅ Chargement terminé avec succès.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
